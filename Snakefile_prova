"""
snoMatcher: C/D Box snoRNA Detection Pipeline
A Snakemake workflow for identifying C/D box snoRNA genes in the human genome
"""

import os
from pathlib import Path

# ============================================================================
# Configuration
# ============================================================================

configfile: "config.yaml"

# Validate required config parameters
# Config file needs to define input files and options
required_params = ["input_files", "generate_plots", "export_tables"]
for param in required_params:
    if param not in config:
        raise ValueError(f"Missing required config parameter: {param}")

# ============================================================================
# Global Variables
# ============================================================================

RESULTS_DIR = Path("results")
PLOTS_DIR = RESULTS_DIR / "plots"
TABLES_DIR = RESULTS_DIR / "tables"
INTERMEDIATE_DIR = RESULTS_DIR / "intermediate"
MODELS_DIR = RESULTS_DIR / "models"
FINAL_DIR = RESULTS_DIR / "final"

# Create output directories
for directory in [PLOTS_DIR, TABLES_DIR, INTERMEDIATE_DIR, MODELS_DIR, FINAL_DIR]:
    directory.mkdir(parents=True, exist_ok=True)

# ============================================================================
# Helper Functions to Generate Dynamic Outputs of the Pipeline based on the Parameter chosen in the Config File
# ============================================================================

def get_plot_outputs():
    """Generate list of plot outputs based on config"""
    if not config.get("generate_plots", True):
        return []
    
    plots = [
        PLOTS_DIR / "all_logos.pdf",
        PLOTS_DIR / "guide_width.pdf",
        PLOTS_DIR / "box_mismatch_distribution.pdf",
        PLOTS_DIR / "all_distance.pdf",
        PLOTS_DIR / "all_distance_distributions.pdf",
        PLOTS_DIR / "motif_score_snoDB_distribution.pdf",
        PLOTS_DIR / "up_motif_score_distribution.pdf",
        PLOTS_DIR / "down_motif_score_distribution.pdf"
    ]
    return [str(p) for p in plots]

def get_table_outputs():
    """Generate list of table outputs based on config"""
    if not config.get("export_tables", True):
        return []
    
    tables = [
        TABLES_DIR / "pfm_cbox_snoDb.csv",
        TABLES_DIR / "pfm_cbox_prime_snoDb.csv",
        TABLES_DIR / "pfm_dbox_snoDb.csv",
        TABLES_DIR / "pfm_dbox_prime_snoDb.csv"
    ]
    return [str(t) for t in tables]

def get_model_outputs():
    """Generate list of model outputs based on config"""
    #to ne updated
    model_type = config.get("machine_learning", {}).get("model", "rf", "xgboost", "all")
    
    models = {
        "rf": MODELS_DIR / "rf_model.RData",
        "svm": MODELS_DIR / "svm_model.RData",
        "xgboost": MODELS_DIR / "xgboost_model.RData",
        "all": [
            MODELS_DIR / "rf_model.RData",
            MODELS_DIR / "svm_model.RData",
            MODELS_DIR / "xgboost_model.RData"
        ]
    }
    
    if model_type == "all":
        return [str(m) for m in models["all"]]
    return [str(models.get(model_type, models["rf"]))]

# ============================================================================
# Target Rules
# ============================================================================

rule all:
    """
    Main target: runs the complete snoRNA analysis pipeline
    """
    input:
        # Core data processing
        INTERMEDIATE_DIR / "info_box.RData",
        INTERMEDIATE_DIR / "scores.RData",
        INTERMEDIATE_DIR / "guide.RData",
        INTERMEDIATE_DIR / "snorna_machine_learning.RData",
        
        # Optional outputs
        get_plot_outputs(),
        get_table_outputs(),
        get_model_outputs(),
        
        # Final report
        FINAL_DIR / "analysis_report.html"
    message:
        "Pipeline completed successfully! Results in {RESULTS_DIR}"

rule models_comparison:
    """
    Train all available models for comparison
    """
    input:
        MODELS_DIR / "rf_model.RData",
        MODELS_DIR / "svm_model.RData",
        MODELS_DIR / "xgboost_model.RData",
        FINAL_DIR / "model_comparison.pdf"
    message:
        "All models trained. Comparison available in {FINAL_DIR}/model_comparison.pdf"

# ============================================================================
# Data Processing Rules
# ============================================================================

rule setup:
    """
    Load and preprocess raw snoRNA data
    Generates initial visualizations of box motifs and guide regions
    """
    input:
        sno_db = config["input_files"]["snodb"],
        met_sites = config["input_files"]["met_sites"],
        sno_boxes = config["input_files"]["sno_boxes"]
    output:
        info_box = INTERMEDIATE_DIR / "info_box.RData",
        all_logos = PLOTS_DIR / "all_logos.pdf" if config.get("generate_plots") else [],
        guide_width = PLOTS_DIR / "guide_width.pdf" if config.get("generate_plots") else []
    params:
        generate_plots = config.get("generate_plots", True)
    threads: config.get("threads", 1)
    resources:
        mem_mb = config.get("memory", 4000)
    log:
        "logs/setup.log"
    script:
        "scripts/setup.R"

rule computing_scores:
    """
    Calculate scoring matrices for C/D box motifs
    Performs position frequency matrix analysis and generates score distributions
    """
    input:
        info_box = rules.setup.output.info_box
    output:
        possible_box = INTERMEDIATE_DIR / "possible_boxes.RData",
        scores = INTERMEDIATE_DIR / "scores.RData",
        
        # Conditional outputs for plots
        box_mismatch = PLOTS_DIR / "box_mismatch_distribution.pdf" if config.get("generate_plots") else [],
        all_distance = PLOTS_DIR / "all_distance.pdf" if config.get("generate_plots") else [],
        distance_dist = PLOTS_DIR / "all_distance_distributions.pdf" if config.get("generate_plots") else [],
        motif_score = PLOTS_DIR / "motif_score_snoDB_distribution.pdf" if config.get("generate_plots") else [],
        
        # Conditional outputs for tables
        pfm_c = TABLES_DIR / "pfm_cbox_snoDb.csv" if config.get("export_tables") else [],
        pfm_cp = TABLES_DIR / "pfm_cbox_prime_snoDb.csv" if config.get("export_tables") else [],
        pfm_d = TABLES_DIR / "pfm_dbox_snoDb.csv" if config.get("export_tables") else [],
        pfm_dp = TABLES_DIR / "pfm_dbox_prime_snoDb.csv" if config.get("export_tables") else []
    params:
        generate_plots = config.get("generate_plots", True),
        export_tables = config.get("export_tables", True)
    threads: config.get("threads", 1)
    resources:
        mem_mb = config.get("memory", 8000)
    log:
        "logs/computing_scores.log"
    script:
        "scripts/computing_scores.R"

rule computing_guide:
    """
    Analyze guide sequences and pairing distributions
    Calculates guide region scores based on rRNA complementarity
    """
    input:
        info_box = rules.setup.output.info_box,
        scores = rules.computing_scores.output.scores
    output:
        guide = INTERMEDIATE_DIR / "guide.RData"
    params:
        generate_plots = config.get("generate_plots", True)
    threads: config.get("threads", 1)
    resources:
        mem_mb = config.get("memory", 8000)
    log:
        "logs/computing_guide.log"
    benchmark:
        "benchmarks/computing_guide.txt"
    script:
        "scripts/computing_guide.R"

rule computing_negatives:
    """
    Generate and score negative training examples
    Creates balanced dataset for machine learning by generating synthetic negatives
    """
    input:
        info_box = rules.setup.output.info_box,
        guide = rules.computing_guide.output.guide,
        scores = rules.computing_scores.output.scores,
        negatives = config["input_files"].get("negatives", "data/raw/negatives.csv")
    output:
        snorna_ml = INTERMEDIATE_DIR / "snorna_machine_learning.RData"
    params:
        sample_size = config.get("machine_learning", {}).get("negative_sample_size", 600)
    threads: config.get("threads", 1)
    resources:
        mem_mb = config.get("memory", 8000)
    log:
        "logs/computing_negatives.log"
    # benchmark:
    #     "benchmarks/computing_negatives.txt"
    script:
        "scripts/computing_negatives.R"

# ============================================================================
# Machine Learning Rules
# ============================================================================

rule train_random_forest:
    """
    Train Random Forest classifier for snoRNA prediction
    Uses ranger for efficient RF implementation with feature importance
    """
    input:
        data = rules.computing_negatives.output.snorna_ml
    output:
        model = MODELS_DIR / "rf_model.RData",
        importance = PLOTS_DIR / "rf_importance.pdf" if config.get("generate_plots") else []
    params:
        n_trees = config.get("machine_learning", {}).get("rf_params", {}).get("n_trees", 1000),
        test_size = config.get("machine_learning", {}).get("test_size", 0.2)
    threads: config.get("threads", 4)
    resources:
        mem_mb = config.get("memory", 16000)
    log:
        "logs/train_rf.log"
    # benchmark:
    #     "benchmarks/train_rf.txt"
    script:
        "scripts/rf_script.R"

rule train_svm:
    """
    Train Support Vector Machine for snoRNA classification
    Includes hyperparameter tuning with cross-validation
    """
    input:
        data = rules.computing_negatives.output.snorna_ml
    output:
        model = MODELS_DIR / "svm_model.RData"
    params:
        kernel = config.get("machine_learning", {}).get("svm_params", {}).get("kernel", "radial"),
        test_size = config.get("machine_learning", {}).get("test_size", 0.2)
    threads: config.get("threads", 4)
    resources:
        mem_mb = config.get("memory", 16000)
    log:
        "logs/train_svm.log"
    # benchmark:
    #     "benchmarks/train_svm.txt"
    script:
        "scripts/svm_script.R"

rule train_xgboost:
    """
    Train XGBoost gradient boosting classifier
    Optimized for imbalanced datasets with early stopping
    """
    input:
        data = rules.computing_negatives.output.snorna_ml
    output:
        model = MODELS_DIR / "xgboost_model.RData"
    params:
        nrounds = config.get("machine_learning", {}).get("xgboost_params", {}).get("nrounds", 100),
        test_size = config.get("machine_learning", {}).get("test_size", 0.2)
    threads: config.get("threads", 4)
    resources:
        mem_mb = config.get("memory", 16000)
    log:
        "logs/train_xgboost.log"
    # benchmark:
    #     "benchmarks/train_xgboost.txt"
    script:
        "scripts/xgboost_script.R"

# rule compare_models:
#     """
#     Generate comprehensive comparison of all trained models
#     Creates visualizations and performance metrics table
#     """
#     input:
#         rf = rules.train_random_forest.output.model,
#         svm = rules.train_svm.output.model,
#         xgboost = rules.train_xgboost.output.model,
#         data = rules.computing_negatives.output.snorna_ml
#     output:
#         comparison = FINAL_DIR / "model_comparison.pdf",
#         metrics = TABLES_DIR / "model_metrics.csv"
#     threads: config.get("threads", 1)
#     resources:
#         mem_mb = config.get("memory", 8000)
#     log:
#         "logs/compare_models.log"
#     # benchmark:
#     #     "benchmarks/compare_models.txt"
#     script:
#         "scripts/model_comparison.R"

# ============================================================================
# Reporting Rules
# ============================================================================

# rule generate_report:
#     """
#     Generate final HTML report with all analysis results
#     Includes visualizations, tables, and model performance metrics
#     """
#     input:
#         info_box = rules.setup.output.info_box,
#         scores = rules.computing_scores.output.scores,
#         guide = rules.computing_guide.output.guide,
#         ml_data = rules.computing_negatives.output.snorna_ml,
#         models = get_model_outputs()
#     output:
#         report = FINAL_DIR / "analysis_report.html"
#     params:
#         title = "snoMatcher Analysis Report",
#         author = config.get("report", {}).get("author", "snoMatcher Pipeline")
#     threads: 1
#     resources:
#         mem_mb = 4000
#     log:
#         "logs/generate_report.log"
#     script:
#         "scripts/generate_report.Rmd"

# ============================================================================
# Utility Rules
# ============================================================================

rule clean:
    """
    Remove all generated files and reset to initial state
    """
    shell:
        """
        rm -rf results/ logs/ benchmarks/ .snakemake/
        echo "Cleaned all generated files"
        """

rule clean_models:
    """
    Remove only trained models
    """
    shell:
        """
        rm -rf {MODELS_DIR}/*.RData
        echo "Cleaned model files"
        """

rule clean_intermediate:
    """
    Remove intermediate files but keep final results
    """
    shell:
        """
        rm -rf {INTERMEDIATE_DIR}/*
        echo "Cleaned intermediate files"
        """

# ============================================================================
# Testing Rules
# ============================================================================

rule test_setup:
    """
    Test the setup rule with sample data
    """
    input:
        rules.setup.output.info_box
    shell:
        """
        echo "Setup test completed successfully"
        Rscript -e "load('{input}'); print(summary(snodb_boxes))"
        """

rule test_pipeline:
    """
    Run complete pipeline test on small dataset
    """
    input:
        rules.all.input
    shell:
        """
        echo "Pipeline test completed successfully"
        echo "All required outputs generated"
        """

# ============================================================================
# Configuration
# ============================================================================

onstart:
    print("=" * 80)
    print("snoMatcher Pipeline Starting")
    print("=" * 80)
    print(f"Working directory: {os.getcwd()}")
    print(f"Config file: config.yaml")
    print(f"Threads: {config.get('threads', 1)}")
    print(f"Generate plots: {config.get('generate_plots', True)}")
    print(f"Export tables: {config.get('export_tables', True)}")
    print("=" * 80)

onsuccess:
    print("=" * 80)
    print("Pipeline completed successfully!")
    print(f"Results available in: {RESULTS_DIR}")
    print("=" * 80)

onerror:
    print("=" * 80)
    print("Pipeline failed! Check log files for details:")
    print(f"  logs/")
    print("=" * 80)