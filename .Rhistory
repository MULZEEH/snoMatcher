snoRNA ~ .,
data = train_data,
importance = "permutation", # For feature importance
num.trees = 1000, # to check w
mtry = sqrt(ncol(train_data) - 1),
probability = T
)
#===
#Step 2: Make predition on test data
#===
pred <- predict(model, test_data)
# --------------------------------------
# Step 3: Evaluate performance
# --------------------------------------
preds <- colnames(pred$predictions)[max.col(pred$predictions, ties.method = "first")]
preds <- factor(preds, levels = levels(test_data$snoRNA))
confusionMatrix(preds, test_data$snoRNA, positive = "TRUE")
# Train the Random Forest model
model <- ranger(
snoRNA ~ .,
data = train_data,
importance = "permutation", # For feature importance
num.trees = 5000, # to check w
mtry = sqrt(ncol(train_data) - 1),
probability = T
)
#===
#Step 2: Make predition on test data
#===
pred <- predict(model, test_data)
# --------------------------------------
# Step 3: Evaluate performance
# --------------------------------------
preds <- colnames(pred$predictions)[max.col(pred$predictions, ties.method = "first")]
preds <- factor(preds, levels = levels(test_data$snoRNA))
confusionMatrix(preds, test_data$snoRNA, positive = "TRUE")
# Train the Random Forest model
model <- ranger(
snoRNA ~ .,
data = train_data,
importance = "permutation", # For feature importance
num.trees = 2000, # to check w
mtry = sqrt(ncol(train_data) - 1),
probability = T
)
#===
#Step 2: Make predition on test data
#===
pred <- predict(model, test_data)
# --------------------------------------
# Step 3: Evaluate performance
# --------------------------------------
preds <- colnames(pred$predictions)[max.col(pred$predictions, ties.method = "first")]
preds <- factor(preds, levels = levels(test_data$snoRNA))
confusionMatrix(preds, test_data$snoRNA, positive = "TRUE")
# Train the Random Forest model
model <- ranger(
snoRNA ~ .,
data = train_data,
importance = "permutation", # For feature importance
num.trees = 1000, # to check w
mtry = sqrt(ncol(train_data) - 1),
probability = T
)
#===
#Step 2: Make predition on test data
#===
pred <- predict(model, test_data)
# --------------------------------------
# Step 3: Evaluate performance
# --------------------------------------
preds <- colnames(pred$predictions)[max.col(pred$predictions, ties.method = "first")]
preds <- factor(preds, levels = levels(test_data$snoRNA))
confusionMatrix(preds, test_data$snoRNA, positive = "TRUE")
# Train the Random Forest model
model <- ranger(
snoRNA ~ .,
data = train_data,
importance = "permutation", # For feature importance
num.trees = 500, # to check w
mtry = sqrt(ncol(train_data) - 1),
probability = T
)
#===
#Step 2: Make predition on test data
#===
pred <- predict(model, test_data)
# --------------------------------------
# Step 3: Evaluate performance
# --------------------------------------
preds <- colnames(pred$predictions)[max.col(pred$predictions, ties.method = "first")]
preds <- factor(preds, levels = levels(test_data$snoRNA))
confusionMatrix(preds, test_data$snoRNA, positive = "TRUE")
# Train the Random Forest model
model <- ranger(
snoRNA ~ .,
data = train_data,
importance = "permutation", # For feature importance
num.trees = 1000, # to check w
mtry = sqrt(ncol(train_data) - 1),
probability = T
)
#===
#Step 2: Make predition on test data
#===
pred <- predict(model, test_data)
# --------------------------------------
# Step 3: Evaluate performance
# --------------------------------------
preds <- colnames(pred$predictions)[max.col(pred$predictions, ties.method = "first")]
preds <- factor(preds, levels = levels(test_data$snoRNA))
confusionMatrix(preds, test_data$snoRNA, positive = "TRUE")
help("ranger")
# Load required libraries
library(e1071)  # For SVM
library(caret)
library(ggplot2)
library(dplyr)
# Check if running with Snakemake or in RStudio
# Need to clear the environment first -> TODO(FIX)
rm(snakemake, envir = .GlobalEnv)
if (!exists("snakemake")) {
# need to change the static hardcoded setwd
setwd("C:/Users/Marco/RProject/snoMatcher/")
# Create mock snakemake object for testing in Rstudio
snakemake <- list(
input = list(
snorna_machine_learning = "results/intermediate/snorna_machine_learning.RData"
),
output = list(
),
config = list(
generate_plots = TRUE,
export_tables = TRUE
)
)
# Helper function for mock object
get_input <- function(name) snakemake$input[[name]]
get_output <- function(name) snakemake$output[[name]]
get_config <- function(name) snakemake$config[[name]]
# get_threads <- function() snakemake$threads
("Debug execution")
} else {
# Helper functions for real snakemake object
get_input <- function(name) snakemake@input[[name]]
get_output <- function(name) snakemake@output[[name]]
get_config <- function(name) snakemake@config[[name]]
# get_threads <- function() snakemake@threads
("snakemake execution")
}
load(file = get_input("snorna_machine_learning"))
# Normalize numerical features (e.g., distances)
preproc <- preProcess(snorna_machine_learning, method = c("center", "scale"))
data_norm <- predict(preproc, snorna_machine_learning)
data_norm$snoRNA <- factor(data_norm$snoRNA)
# Split data into training and testing sets
set.seed(123)
train_idx <- createDataPartition(data_norm$snoRNA, p = 0.8, list = FALSE)
train_data <- data_norm[train_idx, ]
test_data <- data_norm[-train_idx, ]
# Train the SVM model
model <- svm(
snoRNA ~ .,
data = train_data,
kernel = "radial",        # RBF kernel (equivalent to Gaussian)
cost = 1,                 # Regularization parameter
gamma = 1/ncol(train_data-1),  # Kernel parameter (default: 1/number of features)
probability = TRUE        # Enable probability estimates
)
#===
# Step 2: Make prediction on test data
#===
pred <- predict(model, test_data, probability = TRUE)
pred_probs <- attr(pred, "probabilities")
# --------------------------------------
# Step 3: Evaluate performance
# --------------------------------------
# For SVM, predictions are already factor levels, no need to extract from probabilities
preds <- pred
confusionMatrix(preds, test_data$snoRNA, positive = "TRUE")
# --------------------------------------
# Step 4: Hyperparameter tuning (optional but recommended for SVM)
# --------------------------------------
# SVM performance is highly dependent on hyperparameters
# You might want to tune cost and gamma parameters
tune_results <- tune(svm,
snoRNA ~ .,
data = train_data,
kernel = "radial",
ranges = list(
cost = c(0.1, 1, 10, 100),
gamma = c(0.001, 0.01, 0.1, 1)
),
tunecontrol = tune.control(cross = 5)
)
# Get best model from tuning
best_model <- tune_results$best.model
# Make predictions with tuned model
pred_tuned <- predict(best_model, test_data, probability = TRUE)
confusionMatrix(pred_tuned, test_data$snoRNA, positive = "TRUE")
# Option 1: Permutation importance (similar concept to RF)
permutation_importance <- function(model, test_data, n_repeats = 10) {
baseline_accuracy <- mean(predict(model, test_data) == test_data$snoRNA)
importance_scores <- c()
feature_names <- names(test_data)[names(test_data) != "snoRNA"]
for (feature in feature_names) {
accuracies <- c()
for (i in 1:n_repeats) {
# Create permuted dataset
test_permuted <- test_data
test_permuted[[feature]] <- sample(test_permuted[[feature]])
# Calculate accuracy with permuted feature
permuted_accuracy <- mean(predict(model, test_permuted) == test_data$snoRNA)
accuracies <- c(accuracies, permuted_accuracy)
}
# Importance = decrease in accuracy when feature is permuted
importance_scores <- c(importance_scores, baseline_accuracy - mean(accuracies))
}
names(importance_scores) <- feature_names
return(importance_scores)
}
# Calculate permutation importance
importance_scores <- permutation_importance(best_model, test_data)
importance_df <- data.frame(
Feature = names(importance_scores),
Importance = importance_scores
) %>% arrange(desc(Importance))
# Plot importance
ggplot(importance_df, aes(x = reorder(Feature, Importance), y = Importance)) +
geom_bar(stat = "identity") +
coord_flip() +
labs(title = "Feature Importance (SVM - Permutation Method)",
x = "Features",
y = "Importance (Accuracy Drop)")
# Load required libraries
library(e1071)  # For SVM
library(caret)
library(ggplot2)
library(dplyr)
# Check if running with Snakemake or in RStudio
# Need to clear the environment first -> TODO(FIX)
rm(snakemake, envir = .GlobalEnv)
if (!exists("snakemake")) {
# need to change the static hardcoded setwd -> maybe i do not need one (script that creates folder and such)
setwd("C:/Users/Marco/RProject/snoMatcher/")
# Create mock snakemake object for testing in Rstudio
snakemake <- list(
input = list(
snorna_machine_learning = "results/intermediate/snorna_machine_learning.RData"
),
output = list(
),
config = list(
generate_plots = TRUE,
export_tables = TRUE
)
)
# Helper function for mock object
get_input <- function(name) snakemake$input[[name]]
get_output <- function(name) snakemake$output[[name]]
get_config <- function(name) snakemake$config[[name]]
# get_threads <- function() snakemake$threads
("Debug execution")
} else {
# Helper functions for real snakemake object
get_input <- function(name) snakemake@input[[name]]
get_output <- function(name) snakemake@output[[name]]
get_config <- function(name) snakemake@config[[name]]
# get_threads <- function() snakemake@threads
("snakemake execution")
}
load(file = get_input("snorna_machine_learning"))
# Normalize numerical features (e.g., distances)
preproc <- preProcess(snorna_machine_learning, method = c("center", "scale"))
data_norm <- predict(preproc, snorna_machine_learning)
data_norm$snoRNA <- factor(data_norm$snoRNA)
# Split data into training and testing sets
set.seed(123)
train_idx <- createDataPartition(data_norm$snoRNA, p = 0.8, list = FALSE)
train_data <- data_norm[train_idx, ]
test_data <- data_norm[-train_idx, ]
# Train the SVM model
model <- svm(
snoRNA ~ .,
data = train_data,
kernel = "radial",        # RBF kernel (equivalent to Gaussian)
cost = 1,                 # Regularization parameter
gamma = 1/ncol(train_data-1),  # Kernel parameter (default: 1/number of features)
probability = TRUE        # Enable probability estimates
)
#===
# Step 2: Make prediction on test data
#===
pred <- predict(model, test_data, probability = TRUE)
pred_probs <- attr(pred, "probabilities")
# --------------------------------------
# Step 3: Evaluate performance
# --------------------------------------
# For SVM, predictions are already factor levels, no need to extract from probabilities
preds <- pred
confusionMatrix(preds, test_data$snoRNA, positive = "TRUE")
# --------------------------------------
# Step 4: Hyperparameter tuning (optional but recommended for SVM)
# --------------------------------------
# SVM performance is highly dependent on hyperparameters
# You might want to tune cost and gamma parameters
tune_results <- tune(svm,
snoRNA ~ .,
data = train_data,
kernel = "radial",
ranges = list(
cost = c(0.1, 1, 10, 100),
gamma = c(0.001, 0.01, 0.1, 1)
),
tunecontrol = tune.control(cross = 5)
)
# Get best model from tuning
best_model <- tune_results$best.model
# Make predictions with tuned model
pred_tuned <- predict(best_model, test_data, probability = TRUE)
confusionMatrix(pred_tuned, test_data$snoRNA, positive = "TRUE")
# Make predictions with tuned model
pred_tuned <- predict(best_model, test_data)
confusionMatrix(pred_tuned, test_data$snoRNA, positive = "TRUE")
# Check if running with Snakemake or in RStudio
# Need to clear the environment first -> TODO(FIX)
rm(snakemake, envir = .GlobalEnv)
if (!exists("snakemake")) {
# need to change the static hardcoded setwd -> maybe i do not need one (script that creates folder and such)
setwd("C:/Users/Marco/RProject/snoMatcher/")
# Create mock snakemake object for testing in Rstudio
snakemake <- list(
input = list(
snorna_machine_learning = "results/intermediate/snorna_machine_learning.RData"
),
output = list(
svm_model = "results/models/svm_model.RData"
),
config = list(
generate_plots = TRUE,
export_tables = TRUE
)
)
# Helper function for mock object
get_input <- function(name) snakemake$input[[name]]
get_output <- function(name) snakemake$output[[name]]
get_config <- function(name) snakemake$config[[name]]
# get_threads <- function() snakemake$threads
("Debug execution")
} else {
# Helper functions for real snakemake object
get_input <- function(name) snakemake@input[[name]]
get_output <- function(name) snakemake@output[[name]]
get_config <- function(name) snakemake@config[[name]]
# get_threads <- function() snakemake@threads
("snakemake execution")
}
save(model, best_model, file = get_output("svm_model"))
save(model, best_model, file = get_output("svm_model"))
library(Biostrings)
library(data.table)
library(dplyr)
library(stringr)
library(writexl)
library(GenomicFeatures)
library(readxl)
library(stringi)
library(seqinr)
library(parallel)
library(ggseqlogo)
library(ggplot2)
library(ggbeeswarm)
library(ggpubr)
# library(seqLogo)
library(ape)
library(tidyr)
library(patchwork)
library(tidyverse)
# Check if running with Snakemake or in RStudio
# Need to clear the environment first -> TODO(FIX)
rm(snakemake, envir = .GlobalEnv)
if (!exists("snakemake")) {
# need to change the static hardcoded setwd
setwd("C:/Users/Marco/RProject/snoMatcher/")
# Create mock snakemake object for testing in Rstudio
snakemake <- list(
input = list(
info_box = "results/intermediate/info_box.RData"
),
output = list(
possible_box = "results/intermediate/possible_boxes.RData",
scores = "results/intermediate/scores.RData",
# sempliemente sovrascritto
# processed_info_box = "results/intermediate/processed_info_box.RData",
#PLOTS
box_mismatch_distribution = "results/plots/box_mismatch_distribution.pdf",
#violin
all_distance = "results/plots/all_distance.pdf",
#"histogram" density
all_distance_distributions = "results/plots/all_distance_distributions.pdf",
motif_score_distribution = "results/plots/motif_score_snoDB_distribution.pdf",
up_motif_score_distribution = "results/plots/up_motif_score_distribution.pdf",
down_motif_score_distribution = "results/plots/down_motif_score_distribution.pdf",
#TABLES
pfm_cbox_snoDb = "results/tables/pfm_cbox_snoDb.csv",
pfm_cbox_prime_snoDb = "results/tables/pfm_cbox_prime_snoDb.csv",
pfm_dbox_snoDb = "results/tables/pfm_dbox_snoDb.csv",
pfm_dbox_prime_snoDb = "results/tables/pfm_dbox_prime_snoDb.csv"
),
config = list(
generate_plots = TRUE,
export_tables = TRUE
)
)
# Helper function for mock object
get_input <- function(name) snakemake$input[[name]]
get_output <- function(name) snakemake$output[[name]]
get_config <- function(name) snakemake$config[[name]]
# get_threads <- function() snakemake$threads
("Debug execution")
} else {
# Helper functions for real snakemake object
get_input <- function(name) snakemake@input[[name]]
get_output <- function(name) snakemake@output[[name]]
get_config <- function(name) snakemake@config[[name]]
# get_threads <- function() snakemake@threads
("snakemake execution")
}
load(file = get_input("info_box"))
#
c <- c(snodb_boxes$c_seq[str_count(snodb_boxes$c_seq) == 7])
c_prime <- c(snodb_boxes$c_prime_seq)
d <- c(snodb_boxes$d_seq)
d_prime <- c(snodb_boxes$d_prime_seq)
#=== DISTANCE for SCOREs ===
snodb_boxes$dist_d_prime_c_prime <- snodb_boxes$c_prime_start - (snodb_boxes$d_prime_start+3)
snodb_boxes$dist_c_d_prime <- snodb_boxes$d_prime_start -
(snodb_boxes$c_start+6)
snodb_boxes$dist_c_prime_d <- snodb_boxes$d_start-
(snodb_boxes$c_prime_start+6)
snodb_boxes$dist_c_d <- snodb_boxes$d_start - (snodb_boxes$c_start+6)
#=== BOX SCOREs ===
prova <-utils::combn(rep(c("C", "T", "G", "A"), 7),7)
prova.str = unique(apply(prova, 2, paste0, collapse=""))
dist.prova1 = sapply(prova.str, function(x) adist(x, "ATGATGA"))
dist.prova2 = sapply(prova.str, function(x) adist(x, "GTGATGA"))
possible_cboxes1 <- prova.str[dist.prova1 <= 4]
possible_cboxes2 <- prova.str[dist.prova2 <= 4]
possible_cboxes <- union(possible_cboxes1, possible_cboxes2)
#=== PFM ===
pfm_c <- consensusMatrix(c, as.prob = T)
pfm_c_prime <- consensusMatrix(c_prime, as.prob = T)
#=== ACTUAL SCOREs ===
cbox_scores <- sapply(possible_cboxes, PWMscoreStartingAt, pwm = as.matrix(pfm_c))
cbox_scores_prop <- cbox_scores/max(cbox_scores)
c_prime_box_scores <- sapply(possible_cboxes, PWMscoreStartingAt, pwm = as.matrix(pfm_c_prime))
c_prime_box_scores_prop <- c_prime_box_scores/max(c_prime_box_scores)
#=== MISMATCH SCOREs ===
snodb_boxes$cbox_mismatches <- pmin(dist.prova1[snodb_boxes$c_seq],
dist.prova2[snodb_boxes$c_seq])
snodb_boxes$cbox_prime_mismatches <- pmin(dist.prova1[snodb_boxes$c_prime_seq],
dist.prova2[snodb_boxes$c_prime_seq])
#load [Cs]scores in snodb main df snodb_boxes
snodb_boxes$c_box_score <- cbox_scores[snodb_boxes$c_seq]
snodb_boxes$cprime_box_score <- c_prime_box_scores[snodb_boxes$c_prime_seq]
#==============================================================
#                D-BOX (and D') SCORE
#==============================================================
prova <-utils::combn(rep(c("C", "T", "G", "A"), 4),4)
prova.str = unique(apply(prova, 2, paste0, collapse=""))
dist.prova = sapply(prova.str, function(x) adist(x, "CTGA"))
possible_dboxes <- prova.str[dist.prova <= 3]
#=== PFM ===
pfm_d <- consensusMatrix(d, as.prob = T)
pfm_d_prime <- consensusMatrix(d_prime, as.prob = T)
#=== ACTUAL SCOREs ===
dbox_scores <- sapply(possible_dboxes, PWMscoreStartingAt,
pwm = as.matrix(pfm_d))
dbox_scores_prop <- dbox_scores/max(dbox_scores)
d_prime_box_scores <- sapply(possible_dboxes, PWMscoreStartingAt,
pwm = as.matrix(pfm_d_prime))
d_prime_box_scores_prop <- d_prime_box_scores/max(d_prime_box_scores)
#=== MISMATCH SCOREs ===
snodb_boxes$dbox_mismatches <- dist.prova[snodb_boxes$d_seq]
snodb_boxes$dbox_prime_mismatches <- dist.prova[snodb_boxes$d_prime_seq]
#load [Ds]scores in snodb main df
snodb_boxes$dprime_box_score <- d_prime_box_scores[snodb_boxes$d_prime_seq]
snodb_boxes$d_box_score <- dbox_scores[snodb_boxes$d_seq]
#=== EXPORTING THE PROCESSED DATA ===
save(possible_cboxes, possible_dboxes, file = get_output("possible_box"))
save(cbox_scores, cbox_scores_prop,
c_prime_box_scores, c_prime_box_scores_prop,
d_prime_box_scores, d_prime_box_scores_prop,
dbox_scores, dbox_scores_prop,
file = get_output("scores"))
# posso ripassarlo nello stesso punto tanto computing_guide e negatives hanno bisogno anche degli score quindi non possono essere eseguiti prima di computing_scores nella pipeline
save(met_sites, snodb_boxes, file = get_input("info_box"))
#==============================================================
#               MOTIVES PLOTS
#==============================================================
# all motifs <- why is it commented ? chris what u hidin?
snodb_boxes$motif_score <- cbox_scores_prop[snodb_boxes$c_seq]+
c_prime_box_scores_prop[snodb_boxes$c_prime_seq]*0.5+
dbox_scores_prop[snodb_boxes$d_seq]+
d_prime_box_scores_prop[snodb_boxes$d_prime_seq]*0.5
ggplot(snodb_boxes, aes(motif_score))+
geom_histogram(fill = "#434384")+
theme_bw(base_size = 20)+
xlab("snoRNA Boxes score")+
ylab("# of events")
# scale_x_continuous(breaks= c(2.8,3, 3.2,3.4,3.6,3.8,4))
ggsave(get_output("motif_score_distribution"), device = cairo_pdf, width = 6, height = 5)
